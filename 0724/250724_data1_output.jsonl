{"file": "label_0_output.jsonl", "chunk_index": 0, "response": "### 요약\n- 회의는 인공지능 모델을 사용하여 회의록에서 필요한 문장을 분류하는 작업에 대한 논의였다. 현재 사용 중인 데이터는 2,000개의 문장으로 구성되어 있으며, 이 데이터는 회의와 관련된 문장(1)과 관련되지 않은 문장(0)으로 라벨링되었다. 그러나 이 데이터는 실제 회의록과는 차이가 있으며, 라벨링 기준이 명확하지 않아 모델 성능이 낮은 것으로 보인다. 다양한 모델(캐시버트, TF-IDF, 로지스틱 회귀, 클로버트, 모놀로그 페이워 일렉트라)을 비교했지만, 정확도 차이가 크지 않았고, 데이터셋의 문제로 인해 모델 선택이 어려운 상황이다. 또한, 인퍼런스 시 실제 데이터의 노이즈 처리가 필요하며, 레이블링 작업을 GPT를 활용해 개선할 계획이다.\n\n### 안건\n1. 제목: 인공지능 모델 학습 데이터 개선\n   - 현재 사용 중인 학습 데이터는 실제 회의록과 차이가 있으며, 라벨링 기준이 명확하지 않아 모델 성능이 낮다. 따라서 데이터셋을 실제 회의록 기반으로 재구성하고, GPT를 활용해 레이블링 작업을 개선해야 한다.\n   - 관련 발언자: SPEAKER_01, SPEAKER_05\n\n2. 제목: 모델 성능 평가 기준 명확화\n   - 현재 모델 평가 기준이 명확하지 않아 성능 비교가 어렵다. 정확도, 리콜, F1 스코어 등 다양한 지표를 고려해 평가 기준을 설정해야 한다.\n   - 관련 발언자: SPEAKER_01, SPEAKER_05\n\n3. 제목: 인퍼런스 시 노이즈 처리 방안 마련\n   - 학습 데이터는 깨끗하지만, 실제 인퍼런스 데이터에는 노이즈가 포함되어 있어 모델이 헷갈릴 수 있다. 이를 해결하기 위해 인퍼런스 시 특수한 처리 방법을 고려해야 한다.\n   - 관련 발언자: SPEAKER_01, SPEAKER_05\n\n4. 제목: 모델 선택 및 비교 방법 개선\n   - 현재 비교 중인 모델들 간의 성능 차이가 크지 않아 선택이 어려운 상황이다. 모델 비교 시 동일한 조건(배치 크기, 에포크 수 등)을 유지하고, 모델 설명(입력/출력)을 명확히 해야 한다.\n   - 관련 발언자: SPEAKER_01, SPEAKER_05\n\n### 업무 분해\n- [인공지능 모델 학습 데이터 개선]: SPEAKER_01, 2023-10-06, 인공지능 모델 학습 데이터 개선\n- [모델 성능 평가 기준 명확화]: SPEAKER_01, 2023-10-06, 모델 성능 평가 기준 명확화\n- [인퍼런스 시 노이즈 처리 방안 마련]: SPEAKER_01, 2023-10-06, 인퍼런스 시 노이즈 처리 방안 마련\n- [모델 선택 및 비교 방법 개선]: SPEAKER_01, 2023-10-06, 모델 선택 및 비교 방법 개선\n\n### 요약\n- 회의는 인공지능 모델을 사용하여 회의록에서 필요한 문장을 분류하는 작업에 대한 논의였다. 현재 사용 중인 데이터는 2,000개의 문장으로 구성되어 있으며, 이 데이터는 회의와 관련된 문장(1)과 관련되지 않은 문장(0)으로 라벨링되었다. 그러나 이 데이터는 실제 회의록과는 차이가 있으며, 라벨링 기준이 명확하지 않아 모델 성능이 낮은 것으로 보인다. 다양한 모델(캐시버트, TF-IDF, 로지스틱 회귀, 클로버트, 모놀로그 페이워 일렉트라)을 비교했지만, 정확도 차이가 크지 않았고, 데이터셋의 문제로 인해 모델 선택이 어려운 상황이다. 또한"}
{"file": "label_0_output.jsonl", "chunk_index": 1, "response": "### 요약  \n- 회의는 AI 모델을 활용한 회의록 문장 분류 작업의 개선 방안을 논의하는 자리였다. 현재 사용 중인 데이터는 2,000개의 문장으로 구성되며, 레이블링 기준이 명확하지 않아 모델 성능이 낮은 것으로 나타났다. GPT를 활용한 레이블링 개선, 데이터셋 재구성, 평가 지표 명확화(정확도, 리콜, F1 스코어), 인퍼런스 시 노이즈 처리 방안, 모델 선택 기준 개선 등이 주요 논의 사항이다. 특히, 레이블링 데이터의 불균형(1이 100개 미만)과 모델의 과적합 문제, 소프트맥스 vs. 시그모이드 함수 선택, 확신도(Confidence) 기준 조절 등 기술적 세부 사항이 강조되었다.  \n\n---\n\n### 안건  \n1. **제목**: GPT 기반 레이블링 데이터 개선  \n   - 현재 레이블링 데이터는 100건만 수작업으로 생성되었으며, GPT를 활용해 대규모 데이터를 생성하고, 이 데이터를 기존 수작업 레이블링 결과와 비교해 모델의 효과성을 검증해야 한다.  \n   - 관련 발언자: SPEAKER_01, SPEAKER_05  \n\n2. **제목**: 모델 평가 지표 명확화 및 해석  \n   - 정확도, 리콜, F1 스코어 등 다양한 지표를 기준으로 모델 성능을 평가해야 하며, 결과 해석(예: 1%포인트 차이의 의미, 과적합 여부)을 명확히 해야 한다.  \n   - 관련 발언자: SPEAKER_01, SPEAKER_05  \n\n3. **제목**: 인퍼런스 시 노이즈 처리 방안 마련  \n   - 학습 데이터는 깨끗하지만, 실제 인퍼런스 데이터에는 노이즈가 포함되어 있어, 전처리 및 수처리 단계에서 이를 처리할 수 있는 방법(예: 확신도 기준 조절, 예외 케이스 로깅)을 고려해야 한다.  \n   - 관련 발언자: SPEAKER_01, SPEAKER_05  \n\n4. **제목**: 모델 선택 및 비교 기준 통일  \n   - 다양한 모델(캐시버트, 클로버트 등)을 비교 중이지만, 동일한 조건(배치 크기, 에포크 수)에서 평가해야 하며, 소프트맥스 vs. 시그모이드 함수"}
{"file": "label_0_output.jsonl", "chunk_index": 2, "response": "### 요약  \n- 회의는 인공지능 모델 학습 데이터 개선, 레이블링 일관성 확보, 인퍼런스 노이즈 처리, 모델 평가 기준 명확화, 프레젠테이션 일정 조율 등을 논의했다.  \n- 현재 레이블링 데이터는 1,700개에서 300개 추가된 2,000개로 구성되지만, 일관성 부족과 학습/평가 데이터 불일치로 인해 정확도가 낮다. GPT 활용 레이블링, 활성 학습(Active Learning), 자가 감독 학습(Self-Supervised Learning) 등 기법을 도입해 데이터 품질을 개선할 계획이다.  \n- 프레젠테이션 일정은 다음 주 화요일(10월 24일)과 목요일(10월 26일)로 확정되었으며, 트랜스포머 인코더, BERT 학습 방식, 옵티마이저 선택(Adam Warmup vs. Lamb) 등 기술적 내용을 발표해야 한다.  \n\n---\n\n### 안건  \n1. **제목**: 레이블링 데이터 일관성 및 품질 개선  \n   - 현재 레이블링 데이터는 1,700개에서 300개 추가된 2,000개로 구성되지만, 일관성 부족(예: 학습 데이터는 1이지만 평가 데이터는 0/2)으로 인해 모델 성능이 낮다. GPT를 활용해 대규모 레이블링 데이터를 생성하고, 활성 학습(Active Learning)을 통해 모델이 헷갈리는 데이터만 수작업으로 레이블링하는 방식을 도입해야 한다.  \n   - 관련 발언자: SPEAKER_01, SPEAKER_05  \n\n2. **제목**: 인퍼런스 시 노이즈 처리 방안 마련  \n   - 학습 데이터는 깨끗하지만, 실제 인퍼런스 데이터에는 노이즈가 포함되어 있어 모델이 헷갈릴 수 있다. 확신도(Confidence) 기준 조절, 예외 케이스 로깅, 옵티마이저 선택(Adam Warmup vs. Lamb) 등을 고려해 처리 방안을 마련해야 한다.  \n   - 관련 발언자: SPEAKER_01, SPEAKER_05  \n\n3. **제목**: 모델 평가 기준 명확화 및 해석  \n   - 정확도, 리콜, F1 스코어 등 다양한 지표로 모"}
