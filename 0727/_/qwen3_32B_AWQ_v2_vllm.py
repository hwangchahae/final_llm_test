# !pip install vllm

import os, json, re
from glob import glob
from tqdm import tqdm
from transformers import AutoTokenizer
from vllm import LLM, SamplingParams
import torch

# âœ… 1. VLLM ëª¨ë¸ ë¡œë“œ (ë³€ê²½ë¨)
model_path = "Qwen/Qwen3-32B-AWQ"

# VLLM ì—”ì§„ ì´ˆê¸°í™”
llm = LLM(
    model=model_path,
    quantization="awq_marlin",  # ë” ë¹ ë¥¸ awq_marlin ì‚¬ìš©
    tensor_parallel_size=1,
    max_model_len=16384,
    gpu_memory_utilization=0.9,
    trust_remote_code=True,
    enforce_eager=False,
)

# í† í¬ë‚˜ì´ì €ëŠ” ë³„ë„ë¡œ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True
)

# ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° ì„¤ì •
sampling_params = SamplingParams(
    temperature=0.1,
    max_tokens=2048,
    stop=None
)

def clean_text(text):
    if not text:
        return ""
    
    # íŠ¹ì • íƒœê·¸ë“¤ë§Œ ì œê±°
    text = re.sub(r'\[TGT\]', '', text)
    text = re.sub(r'\[/TGT\]', '', text)

    # ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

# âœ… 2. JSONL ë¡œë“œ 
def load_jsonl(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return [
            {
                "speaker": json.loads(line).get("speaker"),
                "text": clean_text(json.loads(line).get("text"))  # íƒœê·¸ ì œê±°
            }
            for line in f if "text" in json.loads(line)
        ]


# âœ… 3. ì²­í¬ ë¶„í•  
def chunk_text(utterances, max_tokens=5000, stride=512):
    input_ids = []
    metadata = []

    for utt in utterances:
        tokens = tokenizer.encode(utt["text"], add_special_tokens=False)
        input_ids.extend(tokens)
        metadata.extend([utt["speaker"]] * len(tokens))

    chunks = []
    speakers_per_chunk = []

    i = 0
    while i < len(input_ids):
        chunk_ids = input_ids[i:i + max_tokens]
        chunk_speakers = metadata[i:i + max_tokens]

        chunk_text = tokenizer.decode(chunk_ids)
        unique_speakers = list(set(chunk_speakers))

        chunks.append(chunk_text)
        speakers_per_chunk.append(unique_speakers)

        i += max_tokens - stride

    return list(zip(chunks, speakers_per_chunk))


# âœ… 4. ìš”ì•½ ìƒì„± í•¨ìˆ˜ (VLLM ë°©ì‹ìœ¼ë¡œ ë³€ê²½)
def generate(prompt):
    # VLLM ì¶”ë¡ 
    outputs = llm.generate([prompt], sampling_params)
    result = outputs[0].outputs[0].text.strip()
    
    # 'ìš”ì•½' ì´í›„ ë‚´ìš©ë§Œ ì¶”ì¶œ
    match = re.search(r"(### ìš”ì•½[\s\S]*)", result)
    return match.group(1).strip() if match else result


# âœ… 5. ì „ì²´ ì²˜ë¦¬ (ë™ì¼)
def create_training_dataset(input_dir_pattern, output_jsonl):
    file_paths = glob(input_dir_pattern)
    with open(output_jsonl, "w", encoding="utf-8") as f_out:
        for file_path in tqdm(file_paths, desc="ğŸ“‚ ì „ì²´ íŒŒì¼ ì²˜ë¦¬ ì§„í–‰"):
            print(f"\nğŸ“ ì²˜ë¦¬ ì¤‘: {file_path}")
            utterances = load_jsonl(file_path)
            chunks = chunk_text(utterances)

            summary_accum = ""
            for idx, (chunk, speakers) in enumerate(tqdm(chunks, desc=f"ğŸ§© ì²­í¬ ì²˜ë¦¬ ({os.path.basename(file_path)})", leave=False)):
                participants_str = ", ".join(speakers)

                prompt = f"""
ë‹¤ìŒì€ íšŒì˜ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.

[ì°¸ì—¬ì]
{participants_str}

[íšŒì˜ ì²­í¬]
{chunk}

[ì´ì „ê¹Œì§€ì˜ ìš”ì•½]
{summary_accum}

1. ì´ íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜.
2. ì•ˆê±´ì´ ìˆë‹¤ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬í•´ì¤˜.
3. ê° ì•ˆê±´ì— ëŒ€í•´ í•„ìš”í•œ ì‘ì—…ë“¤ì„ ë¶„í•´í•´ì¤˜. (ëˆ„ê°€, ë¬´ì—‡ì„, ì–¸ì œê¹Œì§€)

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¤˜:

### ìš”ì•½
- ...

### ì•ˆê±´
1. ì œëª©: ...
   - ì„¸ë¶€ ì„¤ëª…
   - ê´€ë ¨ ë°œì–¸ì

### ì—…ë¬´ ë¶„í•´
- [ì—…ë¬´]: ë‹´ë‹¹ì, ë§ˆê°ì¼, ê´€ë ¨ ì•ˆê±´
"""
                response = generate(prompt)
                json.dump({
                    "file": os.path.basename(file_path),
                    "chunk_index": idx,
                    "response": response
                }, f_out, ensure_ascii=False)
                f_out.write("\n")
                summary_accum = response + "\n"


# âœ… 6. ì‹¤í–‰ ì§„ì…ì  (ë™ì¼)
if __name__ == "__main__":
    create_training_dataset(
        "/workspace/250724_data1_input.jsonl",   
        "/workspace/250727_data1_output.jsonl"
    )