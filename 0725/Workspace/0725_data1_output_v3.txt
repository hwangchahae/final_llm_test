SPEAKER_05: 세계부지 모델 전철이가 이번 주까지예요?
SPEAKER_01: 전철이 이번 주까지가 맞습니다.
SPEAKER_05: 이공식 모델 습도 이번 주까지네요?
SPEAKER_01: 네 맞습니다 일단은 저희 금요일까지로 알고 있는데 네 조금 시간이 빠듯한 부분이 있습니다 그래서 제가 지금 보내드린 거가 저희 산출물 관리하는 구글 스프리드 시트 인데요
SPEAKER_01: 여기 보면 주차라고 되어 있는 게 저희 제출하는 주차고 이번 주가 3주차여서 지금 5개 있습니다.
SPEAKER_01: 다른 조우들도 저희랑 조금 비슷한 상황이긴 한데요.
SPEAKER_01: 인공지능을 전혀 생각 안 하고 채집티 API를 생각하고 있다가 멘토님들이 이런 이런 부분들 넣는 게 좋겠다 해가지고 지금 오늘부터 들어간 팀들도 있고 몇몇 군대에서 그런 얘기를 들었는데 거의 다 버튼 모델을 기반으로 생각을 하고 있더라고요.
SPEAKER_05: 이번에 설명드린 대로만 얘기한다면 버튼 모델이 되겠네요.
SPEAKER_01: , 일단 저 인공지능 데이터 전설의 결과서는 오늘 제가 초안을 작성을 했는데, 이거 일단 제가 보여드리면서 같이 말씀을 나눌까요?
SPEAKER_05: 된 것도 보고, 모델 쪽은 봐야 될 것 같네요.
SPEAKER_01: 일단 제가 이거 방금 제가 드렸었던 데에 3팀 탭에서 보시면 저희 인공지능 데이터 전체 결과에서 제가 링크 올려 놓은 게 있거든요.
SPEAKER_01: 웬토님한테 그 얘기를 듣고 나서 저희가 버트 모델을 가지고서 학습을 조금 파인 튜닝을 해봤는데
SPEAKER_01: 여러 가지 모델들을 저희가 찾아봤었거든요.
SPEAKER_01: 그랬는데 저희가 그날 막 얘기했었던 거에도 단어 사전을 만들어서 단어 빈도수로 한번 해볼까 하는 얘기도 있었고 문맥 판단이라든가 이런 것들도 있었고 해서 여러 가지 찾아봐서 저희 일단 4개의 모델을 비교하는 것으로 얘기를 했어요.
SPEAKER_01: 일단 첫 번째는 범위 캐시버트랑 그다음에 TF-IDF 이거는 이제 단어 빈도수
SPEAKER_01: 로에서 로지스틱이랑 로지스틱 회계로 분류하는 모델 그리고 클로버트하고 모놀로그 페이워 일렉트라 요거는 제가 처음 봤는데 요거는 GPT가 알려줘 가지고 한번 해 봤거든요 그래서 이렇게 네 가지 모...
SPEAKER_05: 네네 나머지 KC버튼 버튼 프로젝트나 같은 경우에는 비교되면 한 번도 봐야될 것 같고 KC버튼을 선정하기에는 뭘까요?
SPEAKER_01: 저희가 그때 얘기했었던 것 중에서 이 회의에서 자주 나오는 단어를 중요도로 해가지고 해보는 건 어떤가라는 얘기가 저희끼리 있었거든요.
SPEAKER_01: 그래서 시험적으로 한번 해본 겁니다.
SPEAKER_01: 이거는 다른 모델인 걸 저도 알긴 하는데 단어 빈도를 했을 때는 어떤 결과가 나올지 궁금해가지고 넣어봤던 거고요.
SPEAKER_05: 당연히 딥러닝이 안 들어가니까 빠르겠죠.
SPEAKER_01: 일단은 버트 모델들도 제가 이 클루 라든가 모놀로그 코어 엘렉트라 같은 경우는 제가 써본 적이 없어서 그 GBT로 제가 조금 찾아보면서 공부를 했었거든요. [

=== 청크 구분 ===

SPEAKER_01: 일단 첫 번째는 범위 캐시버트랑 그다음에 TF-IDF 이거는 이제 단어 빈도수
SPEAKER_01: 로에서 로지스틱이랑 로지스틱 회계로 분류하는 모델 그리고 클로버트하고 모놀로그 페이워 일렉트라 요거는 제가 처음 봤는데 요거는 GPT가 알려줘 가지고 한번 해 봤거든요 그래서 이렇게 네 가지 모...
SPEAKER_05: 네네 나머지 KC버튼 버튼 프로젝트나 같은 경우에는 비교되면 한 번도 봐야될 것 같고 KC버튼을 선정하기에는 뭘까요?
SPEAKER_01: 저희가 그때 얘기했었던 것 중에서 이 회의에서 자주 나오는 단어를 중요도로 해가지고 해보는 건 어떤가라는 얘기가 저희끼리 있었거든요.
SPEAKER_01: 그래서 시험적으로 한번 해본 겁니다.
SPEAKER_01: 이거는 다른 모델인 걸 저도 알긴 하는데 단어 빈도를 했을 때는 어떤 결과가 나올지 궁금해가지고 넣어봤던 거고요.
SPEAKER_05: 당연히 딥러닝이 안 들어가니까 빠르겠죠.
SPEAKER_01: 일단은 버트 모델들도 제가 이 클루 라든가 모놀로그 코어 엘렉트라 같은 경우는 제가 써본 적이 없어서 그 GBT로 제가 조금 찾아보면서 공부를 했었거든요.
SPEAKER_01: 그랬는데 거기에서 이제 정리해줬었던 내용을 가지고서 이 얘 얘가 이런 거가 있구나라는 거를 알고선 여기다 적어 놓은 부분인데요.
SPEAKER_05: 그럼 전 GPT가 답변하는 내용이라는 건가요?
SPEAKER_01: 네 일단 GPT에게 제가 교육을 부탁을 해서 얘가 정리를 해줬습니다.
SPEAKER_05: 네, 그러니까 TF-IDF 빼고는 이게 맞다고 할 수 있는지가 지금 저도 헷갈리거든요.
SPEAKER_01: 요기는 제가 지금 지워놓고 요것도 지워놓고 이후는 더 보강해서 넣도록 하겠습니다.
SPEAKER_05: 그리고 코일렉트라고 생각하시면 되겠는데 모델 사이즈가 지금 다 다를 것 같거든요?
SPEAKER_05: 모델 사이즈 다 명시해주시고 모델 사이즈가 다른 걸 비교하잖아요.
SPEAKER_01: 그래서 Embedding, Encoder, Classification Heads 같은 경우는 제가 맨 처음에 했었던 그 캐시버트를 기준으로 해서 적었고요.
SPEAKER_01: 나머지 애들도 가능하면 거의 같은 조건에서 할 수 있게 물론 로지스틱은 아니었지만 애폭이라든가 배치 크기라든가 이런 거는 맞춰놨습니다 그래서 같은 조건에 같은 데이터로 실험을 했고요 애폭을 시비...
SPEAKER_01: 애폭 이거 조기 종류가 있어가지고 일부러 시브로 잡았습니다 그랬는데 조기 종류가 멈췄나요?
SPEAKER_01: 예 다 멈췄는데 그 위쪽에서
SPEAKER_01: 코일렉트라, 이거가 9f까지 갔었어요.
SPEAKER_01: 다른 거는 5나 2 사이에서 멈췄는데, 제만 9까지 가서 멈추더라고요.
SPEAKER_01: 그래서 일단은 여유있게 시부로 잡아놓기는 했는데, 실제로 해봤을 때

=== 청크 구분 ===

PEAKER_01: 요기는 제가 지금 지워놓고 요것도 지워놓고 이후는 더 보강해서 넣도록 하겠습니다.
SPEAKER_05: 그리고 코일렉트라고 생각하시면 되겠는데 모델 사이즈가 지금 다 다를 것 같거든요?
SPEAKER_05: 모델 사이즈 다 명시해주시고 모델 사이즈가 다른 걸 비교하잖아요.
SPEAKER_01: 그래서 Embedding, Encoder, Classification Heads 같은 경우는 제가 맨 처음에 했었던 그 캐시버트를 기준으로 해서 적었고요.
SPEAKER_01: 나머지 애들도 가능하면 거의 같은 조건에서 할 수 있게 물론 로지스틱은 아니었지만 애폭이라든가 배치 크기라든가 이런 거는 맞춰놨습니다 그래서 같은 조건에 같은 데이터로 실험을 했고요 애폭을 시비...
SPEAKER_01: 애폭 이거 조기 종류가 있어가지고 일부러 시브로 잡았습니다 그랬는데 조기 종류가 멈췄나요?
SPEAKER_01: 예 다 멈췄는데 그 위쪽에서
SPEAKER_01: 코일렉트라, 이거가 9f까지 갔었어요.
SPEAKER_01: 다른 거는 5나 2 사이에서 멈췄는데, 제만 9까지 가서 멈추더라고요.
SPEAKER_01: 그래서 일단은 여유있게 시부로 잡아놓기는 했는데, 실제로 해봤을 때 그렇게 나왔었다는 결과가 있었습니다.
SPEAKER_01: 그리고 이게 이제 학습 결과인데요 일단은 K시버트가 어퀴러시랑 프리시전이랑 F1스코어에서는 월등하게까지는 아니지만 제일 높은 점수를 얻었고 리콜에서는 조금 낮게 나오더라고요 리콜은 KO 엘리트라...
SPEAKER_01: 네네 요거는 그 제가 거기에서 기록을 한 게 스텝 100 스텝마다 이제 기록을 하게 해놨는데 400 스텝에서 가장 최고 점수가 나와서 오해 포크에서 조기 종료가 됐습니다 우측은 베리데이션 어클러...
SPEAKER_01: 로지스틱 같은 경우는 이런 식으로 이거는 점점 성능이 안 좋아지는 결과가 나왔고 CLC, 클루버트 같은 경우는 E-Epoch에서 바로 조기 종료가 됐고요.
SPEAKER_01: 200 스텝에서 제일 좋은 점수가 나왔구요 그 다음에 코어 엘렉트라가 이게 이제 9f 까지 갔었는데 900 스텝에서 점수가 1100하고 조금 애매하긴 한데 900이 조금 더 우세한 것 같더라구요...
SPEAKER_05: 아래까지 다 봤고, 어떻게 해석했는지 알았는데 이거 데이터 어떻게 넣었는지에 대한 설명이 하나도 없네요.
SPEAKER_01: , 데이터 넣은 거요?
SPEAKER_05: 모델 설명 시에 모델의 입력과 출력은 무조건 설명이 들어가야 돼요, 기본적으로.
SPEAKER_05: 입력과 출력은 무조건 설명이 들어가야 돼요.
SPEAKER_05: 지금 이게 어떻게 구성된 건지 알아야 될 것 같거든요?
SPEAKER_01: 일단은 제가 2천 개를 데이터를 넣었는데 문장하고 라벨로 되어 있구요.
SPEAKER_01: CSB 파일이었구요.
SPEAKER_01: 여기 있는 데이터들을 1이랑 0으로 되어 있는 것을 해서 총 합쳐서 2천 개를 넣었고 그 다음에 회의와 연

=== 청크 구분 ===

SPEAKER_01: 로지스틱 같은 경우는 이런 식으로 이거는 점점 성능이 안 좋아지는 결과가 나왔고 CLC, 클루버트 같은 경우는 E-Epoch에서 바로 조기 종료가 됐고요.
SPEAKER_01: 200 스텝에서 제일 좋은 점수가 나왔구요 그 다음에 코어 엘렉트라가 이게 이제 9f 까지 갔었는데 900 스텝에서 점수가 1100하고 조금 애매하긴 한데 900이 조금 더 우세한 것 같더라구요...
SPEAKER_05: 아래까지 다 봤고, 어떻게 해석했는지 알았는데 이거 데이터 어떻게 넣었는지에 대한 설명이 하나도 없네요.
SPEAKER_01: , 데이터 넣은 거요?
SPEAKER_05: 모델 설명 시에 모델의 입력과 출력은 무조건 설명이 들어가야 돼요, 기본적으로.
SPEAKER_05: 입력과 출력은 무조건 설명이 들어가야 돼요.
SPEAKER_05: 지금 이게 어떻게 구성된 건지 알아야 될 것 같거든요?
SPEAKER_01: 일단은 제가 2천 개를 데이터를 넣었는데 문장하고 라벨로 되어 있구요.
SPEAKER_01: CSB 파일이었구요.
SPEAKER_01: 여기 있는 데이터들을 1이랑 0으로 되어 있는 것을 해서 총 합쳐서 2천 개를 넣었고 그 다음에 회의와 연관이 있는 것이
SPEAKER_01: 850개, 850개씩 그 연관이 있는 것과 없는 것이 들어가 있고 300개는 조금 애매한 문장들이 들어가 있습니다 이게 회의와 연관이 있을 수도 있는데 그 문맥에 따라서는 회의와 연관이 있지만 ...
SPEAKER_01: 라는 부분들은 어떨 때 어떤 그 회의를 시작할 때 보면 굉장히 중요한 말이지만
SPEAKER_01: 책임자를 찾거나 그럴 때는 중요한 말이지만 회를 시작할 때는 확인하는 차원이잖아요.
SPEAKER_01: 그런 것들까지 포함해서 총 2,000개의 데이터를 넣었고요.
SPEAKER_05: 여기 1과 0에 대한 정의가 뭐예요?
SPEAKER_01: 일단 1은 회의에 필요한 문장들이고 0 같은 경우는 필요 없는 문장으로 넣었거든요.
SPEAKER_05: 필요하다는 정의가 뭐예요?
SPEAKER_01: 이것이 저희가 만드는
SPEAKER_01: 테스크에서 들어가야 되는 내용들을 기준으로 잡고 있고요.
SPEAKER_01: 제목이라든가 담당자라든가 일정이라든가 그리고 거기에서 있어야 되는 세부 내용들 그거와 관련된 것들을 넣었습니다.
SPEAKER_01: 예시로 해가지고 저희가 수동으로 제가 작성한 게 한 50개 정도를 작성을 해가지고 클로드랑 GPT로 해가지고 다 늘렸습니다.
SPEAKER_01: 이거를 라벨 데이터를 저희가 찾아보려고 했는데 아무래도 이런 식의 라벨 데이터가 없어가지고 만드는 데 문제가 있어서 일단 요거가 제가 부적합해 보여요 네네 실제 데이터랑 전혀 안 맞아 보이거든요...
SPEAKER_05: 제가 저번에 말씀드렸던 내용들은 데이터를 아예 새로 만들려고 했던 게 아니라 저희 회의 데이터 CEO가 했던 거 있죠.
SPEAKER_01: 네네네.
SPEAKER_05:

=== 청크 구분 ===

KER_01: 그런 것들까지 포함해서 총 2,000개의 데이터를 넣었고요.
SPEAKER_05: 여기 1과 0에 대한 정의가 뭐예요?
SPEAKER_01: 일단 1은 회의에 필요한 문장들이고 0 같은 경우는 필요 없는 문장으로 넣었거든요.
SPEAKER_05: 필요하다는 정의가 뭐예요?
SPEAKER_01: 이것이 저희가 만드는
SPEAKER_01: 테스크에서 들어가야 되는 내용들을 기준으로 잡고 있고요.
SPEAKER_01: 제목이라든가 담당자라든가 일정이라든가 그리고 거기에서 있어야 되는 세부 내용들 그거와 관련된 것들을 넣었습니다.
SPEAKER_01: 예시로 해가지고 저희가 수동으로 제가 작성한 게 한 50개 정도를 작성을 해가지고 클로드랑 GPT로 해가지고 다 늘렸습니다.
SPEAKER_01: 이거를 라벨 데이터를 저희가 찾아보려고 했는데 아무래도 이런 식의 라벨 데이터가 없어가지고 만드는 데 문제가 있어서 일단 요거가 제가 부적합해 보여요 네네 실제 데이터랑 전혀 안 맞아 보이거든요...
SPEAKER_05: 제가 저번에 말씀드렸던 내용들은 데이터를 아예 새로 만들려고 했던 게 아니라 저희 회의 데이터 CEO가 했던 거 있죠.
SPEAKER_01: 네네네.
SPEAKER_05: 거기서 개궐을 돌여서 네이블링만 하고 제가 말씀드렸었잖아요.
SPEAKER_05: 저렇게 잘 다듬어지고 SVT와 데이지 않고 실제 바라와 맞지 않은 내용들은 실제 데이터를 넣었을 때 워킹하지 않을 가능성이 높거든요.
SPEAKER_05: 목적 데이터가 실제여야 돼요.
SPEAKER_05: 그래서 이게
SPEAKER_05: 트렌드라면 트렌드일 수 있는데 모델의 성능에 따라서 이게 바뀌어요.
SPEAKER_05: 이제 모델 자체가 너무 성능이 안 좋다보니까 지금처럼 데이터를 예쁘게 만들어놓고 학습시켰어요.
SPEAKER_05: SVM이나 그런 거를 학습할 때는.
SPEAKER_05: 버튼이나 이제 nstm 나오면서부터 이 노이즈라는 것도 학습을 하거든요.
SPEAKER_05: 학습때부터는 엄청 깔끔하게 되는데 인퍼런스 데이터에 노이즈가 있으면 이 모델은 헷갈려요.
SPEAKER_05: 이렇게 학습 데이터를 만들었다는 것은 지금 난이도가 너무 쉽고요.
SPEAKER_05: 지금 이제서야 이 데이터를 보니까 이유가 보이는데 학습 결과를 한번 가볼까요?
SPEAKER_05: 요거 자세히 보시면은 힙화 ADF는 현저히 낮으니까 배제할게요.
SPEAKER_05: F1 스코어 기준으로 봤을 때 지금 정확도가 0.1%
SPEAKER_05: 1%포인트가 안 나요, 지금 정도 저희가.
SPEAKER_05: 그럼 썩어 성능을 봤을 때 얘로 선택해도 되는 거 아니에요?
SPEAKER_05: 단순히 정확도만 높다고 좋은 게 아니잖아요.
SPEAKER_05: 이 얘기는 뭐냐면, 저게 이 승무위 모델을 감당할 정도로 테스크가 쉽다는 거예요.

=== 청크 구분 ===

SPEAKER_05: SVM이나 그런 거를 학습할 때는.
SPEAKER_05: 버튼이나 이제 nstm 나오면서부터 이 노이즈라는 것도 학습을 하거든요.
SPEAKER_05: 학습때부터는 엄청 깔끔하게 되는데 인퍼런스 데이터에 노이즈가 있으면 이 모델은 헷갈려요.
SPEAKER_05: 이렇게 학습 데이터를 만들었다는 것은 지금 난이도가 너무 쉽고요.
SPEAKER_05: 지금 이제서야 이 데이터를 보니까 이유가 보이는데 학습 결과를 한번 가볼까요?
SPEAKER_05: 요거 자세히 보시면은 힙화 ADF는 현저히 낮으니까 배제할게요.
SPEAKER_05: F1 스코어 기준으로 봤을 때 지금 정확도가 0.1%
SPEAKER_05: 1%포인트가 안 나요, 지금 정도 저희가.
SPEAKER_05: 그럼 썩어 성능을 봤을 때 얘로 선택해도 되는 거 아니에요?
SPEAKER_05: 단순히 정확도만 높다고 좋은 게 아니잖아요.
SPEAKER_05: 이 얘기는 뭐냐면, 저게 이 승무위 모델을 감당할 정도로 테스크가 쉽다는 거예요.
SPEAKER_05: 음성에서 회의에 관련된 것만 뽑아오는 게 그렇게 쉽지는 않을 거거든요?
SPEAKER_05: 지금 다시 데이터를 가서 보면은 목표 입장에서 봤을 때 특정 키워드가 나오면 선택하는 거랑 마찬가지거든요.
SPEAKER_05: 그래서 그 맵을 이해하고 부유하는 게 아니라 특정 키워드가 나오면 1이고 특정 키워드가 안 나오면 0이다.
SPEAKER_05: 저기 신의지 사례를 적용하는 게 전혀 아닌 것 같아요.
SPEAKER_01: 하긴 이게 제가 오늘 이걸 하고 나서 꽤 점수가 높게 나와가지고
SPEAKER_01: 일단은 왜 이렇게 높지라는 생각도 하긴 했는데 여기 밑에 보면 제가 이렇게 한 문장씩 넣어가지고 그 확신도를 측정을 하긴 했어요 근데 비슷한 문장인데 살짝 뒤에 어미만 바꿨는데 확신도가 확 떨어...
SPEAKER_05: 그거 플러스 이거 오버피팅이 가능성이 큰데 네 아마 이렇게 만들면 평가 데이터랑 박스 데이터랑 큰 차이가 없을 거거든요?
SPEAKER_05: 네네 근데 데이터는 2000거리고 배치 사이즈는 16이었나?
SPEAKER_05: 네 16이었습니다 박스 데이터가 1800건이래요 그럼 1 앱복당 100스텝 정도밖에 안한거네요?
SPEAKER_01: 그러면 에포크를 낮추고 일단은 데이터는 바꾸는 거는 당연히 해야 될 거고 에포크를 조금 낮추고 배치도 조금 낮추는 게 나을까요?
SPEAKER_05: 배치는 그대로 가셔도 되는데 학생 데이터를 일단 바꿔야 될 거 같고요.
SPEAKER_05: 평가 기준을 넣으실 때 일단 테이블에 드리면
SPEAKER_05: 더 기존에 자세하게 설정하세요.
SPEAKER_05: 저 1은 해외와 관련이 있다고 하는데 네.
SPEAKER_05:

=== 청크 구분 ===

SPEAKER_01: 일단은 왜 이렇게 높지라는 생각도 하긴 했는데 여기 밑에 보면 제가 이렇게 한 문장씩 넣어가지고 그 확신도를 측정을 하긴 했어요 근데 비슷한 문장인데 살짝 뒤에 어미만 바꿨는데 확신도가 확 떨어...
SPEAKER_05: 그거 플러스 이거 오버피팅이 가능성이 큰데 네 아마 이렇게 만들면 평가 데이터랑 박스 데이터랑 큰 차이가 없을 거거든요?
SPEAKER_05: 네네 근데 데이터는 2000거리고 배치 사이즈는 16이었나?
SPEAKER_05: 네 16이었습니다 박스 데이터가 1800건이래요 그럼 1 앱복당 100스텝 정도밖에 안한거네요?
SPEAKER_01: 그러면 에포크를 낮추고 일단은 데이터는 바꾸는 거는 당연히 해야 될 거고 에포크를 조금 낮추고 배치도 조금 낮추는 게 나을까요?
SPEAKER_05: 배치는 그대로 가셔도 되는데 학생 데이터를 일단 바꿔야 될 거 같고요.
SPEAKER_05: 평가 기준을 넣으실 때 일단 테이블에 드리면
SPEAKER_05: 더 기존에 자세하게 설정하세요.
SPEAKER_05: 저 1은 해외와 관련이 있다고 하는데 네.
SPEAKER_05: 저게 원리적 원리나온 이유는 입력 토이 데이터가 너무 많기 때문에
SPEAKER_05: 저희가 물속에서 사고나는 티켓을 따거나 무약을 할 때 필요한 데이터를 필요로 하는 거죠.
SPEAKER_05: 그 기준인 거죠.
SPEAKER_01: 일단은 저희가 그 저번에도 얘기했었던 그 LLM에 먹이기에 토큰 수가 너무
SPEAKER_01: 적은 양이니까 일단은 회의록 문장 내에서 필요없는 문장들을 먼저 제하고 그 다음에 남은 문장들을 집어넣는 걸로 얘기를 해서 써가지고 데이터가 제일 먼저 모델을 만나서 분류를 받고 그 다음에 LLM으로 들어가는 과정으로 갑니다.
SPEAKER_05: 그러면은 여러분들 네이블을 1과 0이라고 했을 때 이 내용이 여기 무사히 들어가야 돼요.
SPEAKER_05: 얘는 엄청 큰 범위에서 정리한거고, 방금 LLM에 쓰기 위한 토큰을 줄이기 위해서 사용을 했는데 여기서 한 번 더 나가서 그러면 다음 테스크가 회의 요약이랑 티콘스를 따는게 있기 때문에 이것과 변형있는 것을 뽑아내는게 여러분들 레이블 설정이에요.
SPEAKER_05: 그럼 저기 회의록은 누가 작성했나요?
SPEAKER_01: 이런 부분들이 조금 외매하기는 한데 이게 테스크 내용에는 또 없기는 하거든요.
SPEAKER_01: 회록을 누가 작성했는지는 보통 티켓 만들 때는 안 들어가니까.
SPEAKER_05: 이게 다르게 한 이유가 그 레이블의 목표가 러프해서 그래요.
SPEAKER_05: 다음 테스트가 정의되면 될 것 같고 두 번째는 만약에 여러분들이 이걸 해서 데이터를 만든다고 했을 때
SPEAKER_05: 근데 실제 데이터는 빈번하게 발생하거든요.
SPEAKER_05: 버트가 입력으로 받을 수 있는 포큰의 한계점은 분명히 작아요.
SPEAKER_05: 아마 지금 레이블링 하는 거는 빠르실 것 같아요. [/

=== 청크 구분 ===

SPEAKER_05: 그러면은 여러분들 네이블을 1과 0이라고 했을 때 이 내용이 여기 무사히 들어가야 돼요.
SPEAKER_05: 얘는 엄청 큰 범위에서 정리한거고, 방금 LLM에 쓰기 위한 토큰을 줄이기 위해서 사용을 했는데 여기서 한 번 더 나가서 그러면 다음 테스크가 회의 요약이랑 티콘스를 따는게 있기 때문에 이것과 변형있는 것을 뽑아내는게 여러분들 레이블 설정이에요.
SPEAKER_05: 그럼 저기 회의록은 누가 작성했나요?
SPEAKER_01: 이런 부분들이 조금 외매하기는 한데 이게 테스크 내용에는 또 없기는 하거든요.
SPEAKER_01: 회록을 누가 작성했는지는 보통 티켓 만들 때는 안 들어가니까.
SPEAKER_05: 이게 다르게 한 이유가 그 레이블의 목표가 러프해서 그래요.
SPEAKER_05: 다음 테스트가 정의되면 될 것 같고 두 번째는 만약에 여러분들이 이걸 해서 데이터를 만든다고 했을 때
SPEAKER_05: 근데 실제 데이터는 빈번하게 발생하거든요.
SPEAKER_05: 버트가 입력으로 받을 수 있는 포큰의 한계점은 분명히 작아요.
SPEAKER_05: 아마 지금 레이블링 하는 거는 빠르실 것 같아요.
SPEAKER_05: 심하면 99.1 정도가 나올 수도 있어요.
SPEAKER_05: 인베런스는 어떻게 처리할 건지, 데이터를 언더셀프닝을 했 건지, 아니면 호크로스나 이런 특수한 인베런스를 위한 처리를 했 건지 고민을 해보셔야 돼요.
SPEAKER_05: 우선 버튼 모델의 지금 GPU 성능에 비하면 엄청 가볍잖아요.
SPEAKER_05: 지금 가장 중요한 거는 일단 실 데이터에서 레이블링 하는 거.
SPEAKER_05: , 그래서 GPT 써야죠.
SPEAKER_05: 그때 이게 된 게, 여러분들이 레이블링 하는 건 100건 정도 레이블링 해야 된다.
SPEAKER_05: 그 다음에 GPT로 만들었을 때, 여러분들이 레이블링 한 거랑, 이거 수확이 나오면 이걸 체크하고, 유사하게 나왔다면 이 프롬포터 모델은 실효할 수 있다라고 가정하고, 얘로 레이블링 한 거를 체크한다.
SPEAKER_01: 그러면은 요게 데이터를 데이터량을 어느 정도로 하는 게 좋을까요?
SPEAKER_01: 이게 보니까 다른 팀들도 그렇고 데이터량에 대해서가 되게 다들 천차만별로 다르더라고요.
SPEAKER_05: 어디에서는 5000건으로 한다고 하고 만건으로 한다고 90,000건까지 얘기를 들었는데 가장 좋은 거는 여러분들이 모델이 학습이 다 되는 학습이 됐는데 1회폭이 다 안 돌아왔으면 가장 좋아요.
SPEAKER_01: 근데 그걸 또 검증을 또 저희가 해야 되니까.
SPEAKER_05: 지금 입력데이터는 여러분들이 컨트롤할 필요가 없어요.
SPEAKER_05: 입력데이터 정해져 있잖아요.
SPEAKER_05: 여러분들이 정한 건 레이블에 딱 하나밖에 없어요.
SPEAKER_05: 실제 데이터에서 저희가 대화할 때 학습하기 좋게 끊어서 말하지는 않잖아요.

=== 청크 구분 ===

SPEAKER_05: 그때 이게 된 게, 여러분들이 레이블링 하는 건 100건 정도 레이블링 해야 된다.
SPEAKER_05: 그 다음에 GPT로 만들었을 때, 여러분들이 레이블링 한 거랑, 이거 수확이 나오면 이걸 체크하고, 유사하게 나왔다면 이 프롬포터 모델은 실효할 수 있다라고 가정하고, 얘로 레이블링 한 거를 체크한다.
SPEAKER_01: 그러면은 요게 데이터를 데이터량을 어느 정도로 하는 게 좋을까요?
SPEAKER_01: 이게 보니까 다른 팀들도 그렇고 데이터량에 대해서가 되게 다들 천차만별로 다르더라고요.
SPEAKER_05: 어디에서는 5000건으로 한다고 하고 만건으로 한다고 90,000건까지 얘기를 들었는데 가장 좋은 거는 여러분들이 모델이 학습이 다 되는 학습이 됐는데 1회폭이 다 안 돌아왔으면 가장 좋아요.
SPEAKER_01: 근데 그걸 또 검증을 또 저희가 해야 되니까.
SPEAKER_05: 지금 입력데이터는 여러분들이 컨트롤할 필요가 없어요.
SPEAKER_05: 입력데이터 정해져 있잖아요.
SPEAKER_05: 여러분들이 정한 건 레이블에 딱 하나밖에 없어요.
SPEAKER_05: 실제 데이터에서 저희가 대화할 때 학습하기 좋게 끊어서 말하지는 않잖아요.
SPEAKER_05: 그래서 가비지 2는 없어요.
SPEAKER_05: 가비지 아웃을 잘 세팅해서 그걸 인력으로 넣는 게 여러분들의 핵심이고.
SPEAKER_01: 코드는 이미 있어서요.
SPEAKER_01: 이거를 뽑아내는 것만 하면 될 것 같고 그 뽑아내는 거를 내일이랑 모레 오전 사이에 빨리 한 다음에 열심히 돌려가야죠.
SPEAKER_05: 만약에 0이 메이저 그래쓰고 1이 마이노 그래쓰라고 했을 때 만약에 1이 100개 밖에 안 돼요.
SPEAKER_05: 스페일로 해도 전체 데이터가 1100건 정도밖에 안 되겠죠.
SPEAKER_05: 그럼 예를, 포컬로스 방식이 가장 흔한 방식인데 이런 임패런스를 처리하는 방법들이 몇 가지 있어요.
SPEAKER_05: 이것도 코드는 어렵지 않거든요.
SPEAKER_05: 한두 줄은 보고 CPT가 잘 만들어질 거예요.
SPEAKER_05: 이런 거 다 조사해서 해보시고.
SPEAKER_05: 레이블이 수정했고, 레이블 분고가 어떻게 돼있고, 이 모델을 학습하는 이유가 뭔지가 안 나와 있어요.
SPEAKER_05: 여기 그 내용들이 하나도 없어요.
SPEAKER_01: 데이터와 관련된 내용들 말씀이시죠?
SPEAKER_05: 네, 그리고 제가 모델 결과 해석을 갖고 와달라고 했는데, 결과 해석 부분도 없는 것 같아요.
SPEAKER_04: 결과를 해석해보면 어떤 내용인지 아시죠?
SPEAKER_05: 제가 얘기 드린 대로 위로 올라갔을 때 저 스코어를 봤을 때 자다실 아마 여러분들이 결과를 해석을 했으면 제가 생각한 결론을 바로 도달했을 것 같거든요.
SPEAKER_05: 얘랑 얘랑 스코어 차이가 얼마 안 난다

=== 청크 구분 ===

SPEAKER_05: 스페일로 해도 전체 데이터가 1100건 정도밖에 안 되겠죠.
SPEAKER_05: 그럼 예를, 포컬로스 방식이 가장 흔한 방식인데 이런 임패런스를 처리하는 방법들이 몇 가지 있어요.
SPEAKER_05: 이것도 코드는 어렵지 않거든요.
SPEAKER_05: 한두 줄은 보고 CPT가 잘 만들어질 거예요.
SPEAKER_05: 이런 거 다 조사해서 해보시고.
SPEAKER_05: 레이블이 수정했고, 레이블 분고가 어떻게 돼있고, 이 모델을 학습하는 이유가 뭔지가 안 나와 있어요.
SPEAKER_05: 여기 그 내용들이 하나도 없어요.
SPEAKER_01: 데이터와 관련된 내용들 말씀이시죠?
SPEAKER_05: 네, 그리고 제가 모델 결과 해석을 갖고 와달라고 했는데, 결과 해석 부분도 없는 것 같아요.
SPEAKER_04: 결과를 해석해보면 어떤 내용인지 아시죠?
SPEAKER_05: 제가 얘기 드린 대로 위로 올라갔을 때 저 스코어를 봤을 때 자다실 아마 여러분들이 결과를 해석을 했으면 제가 생각한 결론을 바로 도달했을 것 같거든요.
SPEAKER_05: 얘랑 얘랑 스코어 차이가 얼마 안 난다 라고 했을 때 그럼 얘가 모델이 작은 건 작용한 사실인 거잖아요.
SPEAKER_05: 여기에서 1%포인트의 차이가 얼마나 큰지 여러분들이 보겠죠.
SPEAKER_05: 여기서 느껴지는 건 정확도가 더 높긴 하지만 요약하는데 큰 의미가 없다라고 하면 서버를 요약시키는 게 더 중요한 게 맞는 거고.
SPEAKER_05: 그리고 이런 작용 모델이 좋아지는 이유가 뭘까.
SPEAKER_05: 보다 보면 실제 데이터랑 차이를 봤을 때 변별력이 없구나.
SPEAKER_05: 이거는 제가 여러분들한테 말했는지 기억이 안 나서 4.2.1을 보면 첫 번째 그래프에 이게 스텝을 많이 찍어서 그러는데 베리디션 로스가 첫 백 스텝을 밟았을 때 더 로스가 낮아요.
SPEAKER_05: 트레이닝 노스보다 아래 내려가면 얘도 베리 데이션 노스가 처음에는 더 노스가 낮아요.
SPEAKER_05: 과적합 문제인가요?
SPEAKER_05: 과적합이면 트레이닝 노스가 더 낮아야죠.
SPEAKER_05: 학사 데이터에 가져가서 된 건데 여러분들 이게 100 스텝 단위로 찍어서 그렇지 1 스텝, 10 스텝 단위로 찍었으면 베리에디션 노스가 낮은 걸 더 많이 오랫동안 볼 수 있거든요 그 이유가 뭘까...
SPEAKER_01: 데이터가 모자라서 저렇게 되는 건가요?
SPEAKER_05: 스텝이니까 애초에 원인폭밖에 못 들어왔잖아요 데이터 양해는 생각 못 했을 거예요
SPEAKER_05: , 인베젼스가 심하다고 하면은 트레이딩된 로스가 더 좋았겠죠.
SPEAKER_05: 근데 여기는 지금 레잉벨 빌런스가 너무 좋거든요?
SPEAKER_05: 아까 데이터 눈으로 대충 보기만 해도 0과 1이 잘 섞여있어서 아마 전체 데이터 분포도 똑같을 것 같아요.

=== 청크 구분 ===

5: 이거는 제가 여러분들한테 말했는지 기억이 안 나서 4.2.1을 보면 첫 번째 그래프에 이게 스텝을 많이 찍어서 그러는데 베리디션 로스가 첫 백 스텝을 밟았을 때 더 로스가 낮아요.
SPEAKER_05: 트레이닝 노스보다 아래 내려가면 얘도 베리 데이션 노스가 처음에는 더 노스가 낮아요.
SPEAKER_05: 과적합 문제인가요?
SPEAKER_05: 과적합이면 트레이닝 노스가 더 낮아야죠.
SPEAKER_05: 학사 데이터에 가져가서 된 건데 여러분들 이게 100 스텝 단위로 찍어서 그렇지 1 스텝, 10 스텝 단위로 찍었으면 베리에디션 노스가 낮은 걸 더 많이 오랫동안 볼 수 있거든요 그 이유가 뭘까...
SPEAKER_01: 데이터가 모자라서 저렇게 되는 건가요?
SPEAKER_05: 스텝이니까 애초에 원인폭밖에 못 들어왔잖아요 데이터 양해는 생각 못 했을 거예요
SPEAKER_05: , 인베젼스가 심하다고 하면은 트레이딩된 로스가 더 좋았겠죠.
SPEAKER_05: 근데 여기는 지금 레잉벨 빌런스가 너무 좋거든요?
SPEAKER_05: 아까 데이터 눈으로 대충 보기만 해도 0과 1이 잘 섞여있어서 아마 전체 데이터 분포도 똑같을 것 같아요.
SPEAKER_05: 여러분들 최종 보고로 레잉벨 분포는 넣으셔야 돼요.
SPEAKER_05: 이거 사이키넘의 프리시전 리콜 F1 스코어 리포트라는 게 있어요.
SPEAKER_05: 마이크로 F1이랑 매크로 F1 같이 같이 나오는 거.
SPEAKER_05: 그 표로 사이키넘 코드 한 줄이면 되거든요.
SPEAKER_05: 그걸 넣으면은 레이블링 숫자도 같이 나와요.
SPEAKER_05: 첫번째 드랍아웃인데 이건 큰 원인은 아니에요.
SPEAKER_05: 학습할때는 레이어를 일부밖에 안써요.
SPEAKER_05: 인포핏할때는 모든 레이어를 다 사용합니다.
SPEAKER_05: 합습 로스는?
SPEAKER_04: 합습 로스는 언제 고르죠?
SPEAKER_05: 합습 로스는 매 스텝만 항상 발생하잖아요.
SPEAKER_05: 그럼 백 스텝이 발생할 때 처음에 합습이 AI인데 랜덤한 웨이트에서도 로스가 발생해요.
SPEAKER_05: 저는 백스텝이 학습이 다 된 후에 평가를 하죠.
SPEAKER_05: 이 시점은 저 주황색 트레이닝 로스는 0부터 100스텝까지 사이에 있는 로스인거고 베리션로스는 백스텝이 돼서 나오는 로스에요.
SPEAKER_05: 학습이 더 된 상태고 뒤로 갈수록 트레이닝 로스 내려가는거는 학습 데이터에 더 최적화되고 있기 때문에 내려가는거고 모델이 어느정도 좋아졌기 때문에 내려가는거에요.
SPEAKER_05: 초기에는 여러분들이 지금 스텝라인을 크게 찍었는데 초기에는 베를레이션 호스가 낮은 상태가 오래 지속되는 경우도 있어요.

=== 청크 구분 ===

EAKER_05: 첫번째 드랍아웃인데 이건 큰 원인은 아니에요.
SPEAKER_05: 학습할때는 레이어를 일부밖에 안써요.
SPEAKER_05: 인포핏할때는 모든 레이어를 다 사용합니다.
SPEAKER_05: 합습 로스는?
SPEAKER_04: 합습 로스는 언제 고르죠?
SPEAKER_05: 합습 로스는 매 스텝만 항상 발생하잖아요.
SPEAKER_05: 그럼 백 스텝이 발생할 때 처음에 합습이 AI인데 랜덤한 웨이트에서도 로스가 발생해요.
SPEAKER_05: 저는 백스텝이 학습이 다 된 후에 평가를 하죠.
SPEAKER_05: 이 시점은 저 주황색 트레이닝 로스는 0부터 100스텝까지 사이에 있는 로스인거고 베리션로스는 백스텝이 돼서 나오는 로스에요.
SPEAKER_05: 학습이 더 된 상태고 뒤로 갈수록 트레이닝 로스 내려가는거는 학습 데이터에 더 최적화되고 있기 때문에 내려가는거고 모델이 어느정도 좋아졌기 때문에 내려가는거에요.
SPEAKER_05: 초기에는 여러분들이 지금 스텝라인을 크게 찍었는데 초기에는 베를레이션 호스가 낮은 상태가 오래 지속되는 경우도 있어요.
SPEAKER_05: 드랍아웃은 예를 들어 50%에요.
SPEAKER_05: 학습할 때는 5개의 뉴럴네트워크로만 학습을 하죠.
SPEAKER_05: 이 5개만 사용하는 것은 록스가 발생해요.
SPEAKER_05: 퍼포먼스 할 때는 10개를 다 연합해서 쓰기 때문에 아무래도 레이어를 더 많이 쓰게 되죠.
SPEAKER_05: 더 레이어를 많이 쓰다 보니 웨이트도 많이 되고 모든 게 폭해질 수 밖에 없죠, 일관적으로.
SPEAKER_05: 사실 내 능력이 높은 거고 가장 큰 영향을 할 거라고 말씀드렸던 루스 리턴의 시점에서 발생한 거예요.
SPEAKER_05: 지금은 데이터도 너무 좋고 이래서 크레이닝 루스가 바로바로 떨어져서 첫 시스템을 누던 현상이 발생하는데 어려운 데이터에서
SPEAKER_05: 10스텝으로 찍는다라고 하면은 나중에 이제 자주 보게 될 거예요.
SPEAKER_01: 그러면 잘 된 경우라면은 트렌드 로스가 더 높아요.
SPEAKER_05: 계속 학습을 하고 있는데 학습 메이터가 빠르게 빠르게 변하고 있기 때문에 학습이 빠르게 진행되고 있죠.
SPEAKER_05: 그러면 그 사이에 지금 100 스텝별로 학습을 찍었다고 하면은 그 100 스텝 사이에 학습이 많이 됐기 때문에 베리데이션 노스가 더 내려가는 거예요.
SPEAKER_01: 그렇게 의심하면서는 생각을 안 해봤던 것 같아요.
SPEAKER_05: 4.2.3 보면 프리시안 리콜이 프리시안에서 나왔죠?
SPEAKER_05: 리콜이 더 높다는 거는?
SPEAKER_05: 더 많이 있다는 거예요.
SPEAKER_05: 반대로 4.2.3에 보면 프리시안 리콜이 교차례해서 왔다 갔다 해요.
SPEAKER_01: 둘 다 4

=== 청크 구분 ===

_05: 사실 내 능력이 높은 거고 가장 큰 영향을 할 거라고 말씀드렸던 루스 리턴의 시점에서 발생한 거예요.
SPEAKER_05: 지금은 데이터도 너무 좋고 이래서 크레이닝 루스가 바로바로 떨어져서 첫 시스템을 누던 현상이 발생하는데 어려운 데이터에서
SPEAKER_05: 10스텝으로 찍는다라고 하면은 나중에 이제 자주 보게 될 거예요.
SPEAKER_01: 그러면 잘 된 경우라면은 트렌드 로스가 더 높아요.
SPEAKER_05: 계속 학습을 하고 있는데 학습 메이터가 빠르게 빠르게 변하고 있기 때문에 학습이 빠르게 진행되고 있죠.
SPEAKER_05: 그러면 그 사이에 지금 100 스텝별로 학습을 찍었다고 하면은 그 100 스텝 사이에 학습이 많이 됐기 때문에 베리데이션 노스가 더 내려가는 거예요.
SPEAKER_01: 그렇게 의심하면서는 생각을 안 해봤던 것 같아요.
SPEAKER_05: 4.2.3 보면 프리시안 리콜이 프리시안에서 나왔죠?
SPEAKER_05: 리콜이 더 높다는 거는?
SPEAKER_05: 더 많이 있다는 거예요.
SPEAKER_05: 반대로 4.2.3에 보면 프리시안 리콜이 교차례해서 왔다 갔다 해요.
SPEAKER_01: 둘 다 4.6.3이네요 제가 이거 라벨링을 잘못했네요?
SPEAKER_05: 네 이 얘기는 밸런스가 비슷하기 때문에 프리시언 리콜이 교차할 수 있다는 거거든요?
SPEAKER_05: 저는 이거 밸런스가 비슷하겠네라고 해석을 한 거에요 어깔일 수 있잖아요 모델이 1이 많다고 하면 다이애만 찍어서 리콜이 높아질 가능성이 크거든요 이런 것도 하나의 단서긴 해요 그렇게 되는구나
SPEAKER_05: 그래서 4.2.2 보면 정확도가 안 좋은 부분은 얘는 1을 많이 지었다.
SPEAKER_05: 모든 예측 값을 거의 다 1으로 집었기 때문에 얘는 정확도가 낮은 거다 라고 볼 수 있겠죠.
SPEAKER_05: 여러 가지 해석은 보면서 봐야 됩니다.
SPEAKER_05: 이것도 해석을 하셔야 되는데, 해석은 결과의 해석이 아니라 모델이 왜 정확도가 높으면 왜 높은지, 날씨가 왜 낮은지.
SPEAKER_05: 보통은 여러분이 최적화를 진행시킬 때 모델 더 좋은 거 바꿔볼까, 알고리즘 바꿔볼까로 접근하는 게 아니라 물론 그렇게 하시는 것도 맞는데 이 모델이 만약에 여러분이 최적화, 아니 이 모델, 최적화의 모델을 선정이 됐어요.
SPEAKER_05: 그러면 이 모델이 예측이 틀린 실제 값들 있죠.
SPEAKER_05: 그러면 전처리에 이런 걸 추가해주면 좋겠다.
SPEAKER_05: 전처리에 넣고 모델한테 힌트를 주는 걸 추가해주면 되겠죠.
SPEAKER_05: 이런 방식도 사용할 수 있고 수처리 방식도 있을 수도 있고 모델 이렇게 예측했지만 이런 케이스에는 반대가 왔다.
SPEAKER_05: 그럼 수처리에 무조건 바꿔주는, 리플레이스 해주는 방법도 있겠죠.
SPEAKER_05: 기본적으로 모델을 최적화시킨다고 했을 때는 트레이닝 값을 다 출협해서 보는 게 일반적이에요.

=== 청크 구분 ===

SPEAKER_05: 모든 예측 값을 거의 다 1으로 집었기 때문에 얘는 정확도가 낮은 거다 라고 볼 수 있겠죠.
SPEAKER_05: 여러 가지 해석은 보면서 봐야 됩니다.
SPEAKER_05: 이것도 해석을 하셔야 되는데, 해석은 결과의 해석이 아니라 모델이 왜 정확도가 높으면 왜 높은지, 날씨가 왜 낮은지.
SPEAKER_05: 보통은 여러분이 최적화를 진행시킬 때 모델 더 좋은 거 바꿔볼까, 알고리즘 바꿔볼까로 접근하는 게 아니라 물론 그렇게 하시는 것도 맞는데 이 모델이 만약에 여러분이 최적화, 아니 이 모델, 최적화의 모델을 선정이 됐어요.
SPEAKER_05: 그러면 이 모델이 예측이 틀린 실제 값들 있죠.
SPEAKER_05: 그러면 전처리에 이런 걸 추가해주면 좋겠다.
SPEAKER_05: 전처리에 넣고 모델한테 힌트를 주는 걸 추가해주면 되겠죠.
SPEAKER_05: 이런 방식도 사용할 수 있고 수처리 방식도 있을 수도 있고 모델 이렇게 예측했지만 이런 케이스에는 반대가 왔다.
SPEAKER_05: 그럼 수처리에 무조건 바꿔주는, 리플레이스 해주는 방법도 있겠죠.
SPEAKER_05: 기본적으로 모델을 최적화시킨다고 했을 때는 트레이닝 값을 다 출협해서 보는 게 일반적이에요.
SPEAKER_01: 안 그래도 저희끼리 얘기를 했었던 게 이게 이 밑에다가 제가 적어놓기는 했었는데 이게 확신도가 낮은 것들이 애매한 것들이 많더라고요.
SPEAKER_01: 물론 이게 깨끗한 데이터이기는 했지만 그래서 저희가 그거를 빼내는 거를 할 때 정말 필요 없다고 생각한 것들 빼고 나머지 확신도가 낮은 것들은 요약할 때 포함시켜야 하지 않을까 이런 얘기를 했거든요.
SPEAKER_01: 그러면 거기에는 확신도도 낮지만 중요한 문장이 적혀 있을 수도 있을 것 같아서 그래서 그거를 포함을 시키되 이 제외시킨 애들을 로그로 저장을 해가지고 확인을 한번 해봐야겠다 이런 얘기를 저희끼리...
SPEAKER_01: 아니요, 레퍼런스는 없었고 제가 이거 위에 이거 그리고 확신도 이거를 확인을 계속 하면서 여러 가지 문장들을 되게 다양하게 넣어봤거든요 근데
SPEAKER_01: 진짜 조금 애매한 문장들, 문맥에 따라서는 중요할 수도 있고 아닐 수도 있는 이런 문장들을 거의 다 확신도를 낮게 잡아서 이것들을 다 0으로 얘가 판단했다고 다 무시하는 건 안 될 것 같다라는 생각이 들어서 이렇게 한 거거든요.
SPEAKER_05: 최종 레이어에 엑티베이션 펑션?
SPEAKER_05: 0과 a를 예측할 때 마지막에 한 게 소프트 맥스예요?
SPEAKER_01: 소프트 맥스로 했었던 걸로 네 소프트 맥스 겁니다 잠시만요 이거 어디다 넣어놨는데 어디다가 넣어놨더라 보통은 0과 1이면 시그모이드일텐데 소프트 맥스인가요?
SPEAKER_05: 네 여기는 소프트 맥스로 해놨었습니다 네 보통은 시그모이드 써요 0과 1이 되는 일단 소프트 맥스 하셨으니까 소프트 맥스 기준으로
SPEAKER_05: 그 벤치에서 이제 높은 값을 내리고, 낮은 값은 0으로 바뀌었죠.
SPEAKER_05: 근데 이거를 0과 1로 비교한 게 결국에는 그 0.5 기준으로 비교를 했을 거란 말이에요.
SPEAKER_05: 컴피던스 기준, 쓰레쉬 옵션의 0

=== 청크 구분 ===

SPEAKER_01: 아니요, 레퍼런스는 없었고 제가 이거 위에 이거 그리고 확신도 이거를 확인을 계속 하면서 여러 가지 문장들을 되게 다양하게 넣어봤거든요 근데
SPEAKER_01: 진짜 조금 애매한 문장들, 문맥에 따라서는 중요할 수도 있고 아닐 수도 있는 이런 문장들을 거의 다 확신도를 낮게 잡아서 이것들을 다 0으로 얘가 판단했다고 다 무시하는 건 안 될 것 같다라는 생각이 들어서 이렇게 한 거거든요.
SPEAKER_05: 최종 레이어에 엑티베이션 펑션?
SPEAKER_05: 0과 a를 예측할 때 마지막에 한 게 소프트 맥스예요?
SPEAKER_01: 소프트 맥스로 했었던 걸로 네 소프트 맥스 겁니다 잠시만요 이거 어디다 넣어놨는데 어디다가 넣어놨더라 보통은 0과 1이면 시그모이드일텐데 소프트 맥스인가요?
SPEAKER_05: 네 여기는 소프트 맥스로 해놨었습니다 네 보통은 시그모이드 써요 0과 1이 되는 일단 소프트 맥스 하셨으니까 소프트 맥스 기준으로
SPEAKER_05: 그 벤치에서 이제 높은 값을 내리고, 낮은 값은 0으로 바뀌었죠.
SPEAKER_05: 근데 이거를 0과 1로 비교한 게 결국에는 그 0.5 기준으로 비교를 했을 거란 말이에요.
SPEAKER_05: 컴피던스 기준, 쓰레쉬 옵션의 0.5.
SPEAKER_05: 조절하는 것도 좋은데 컴피던스를 쓰레쉬 옵션으로 바꾸겠다는 건 엄청 예민한 작업이에요.
SPEAKER_05: 여러분들이 이 판단 기준의 0.4로 내리거나 줄였을 때 이거를 잘 보셔야 되거든요.
SPEAKER_05: 얘는 그때 흥률값이 아니에요.
SPEAKER_05: 모델이 예측한 예측값이거든요.
SPEAKER_05: 그 calibrated라고 모델의 예측값을 흥률값처럼 보이게 해주는 이런 알고리심들이 따로 있어요.
SPEAKER_05: 얘는 무직값이지 흥률값이 아니다 라는 거 첫번째고 두번째 컴피던스를 믿으면 안되는게 여러분들 지금 스코어가 좋잖아요.
SPEAKER_05: 그러면은 애매한 데이터가 올라왔을 때 얘가 1인 것 같아요.
SPEAKER_05: 그러면은 로직 값을 0.5로 할까요?
SPEAKER_05: 그래서 모델 정도가 좋아지면 모델들은 대체로 오버콤비던스라는 문제가 생기게 발생해요.
SPEAKER_01: 이런 상황에서 여러분들이 센싱분들을 벌어버린다는데 얼마나 예민한 건 흔들리는 건지...
SPEAKER_05: 노스를 밖에 주기 때문에.
SPEAKER_01: 네 일단 데이터 바꾸고 일단 실험도 다시 해야되니까 이거는 다 바꾸기는 해야겠는데 아까 말씀해주셨던 어떤 데이터를 어떻게 넣었는지에 대한 부분이랑 그 다음에 모델도 라지 모델을 한두개 정도 더 ...
SPEAKER_05: 분명히 인베너스 발생할 거거든요.
SPEAKER_05: 그래서 그 문제 있으면은 금요일에 가고 목요일에 요청을 하시거든요.
SPEAKER_05:

=== 청크 구분 ===

SPEAKER_05: 얘는 무직값이지 흥률값이 아니다 라는 거 첫번째고 두번째 컴피던스를 믿으면 안되는게 여러분들 지금 스코어가 좋잖아요.
SPEAKER_05: 그러면은 애매한 데이터가 올라왔을 때 얘가 1인 것 같아요.
SPEAKER_05: 그러면은 로직 값을 0.5로 할까요?
SPEAKER_05: 그래서 모델 정도가 좋아지면 모델들은 대체로 오버콤비던스라는 문제가 생기게 발생해요.
SPEAKER_01: 이런 상황에서 여러분들이 센싱분들을 벌어버린다는데 얼마나 예민한 건 흔들리는 건지...
SPEAKER_05: 노스를 밖에 주기 때문에.
SPEAKER_01: 네 일단 데이터 바꾸고 일단 실험도 다시 해야되니까 이거는 다 바꾸기는 해야겠는데 아까 말씀해주셨던 어떤 데이터를 어떻게 넣었는지에 대한 부분이랑 그 다음에 모델도 라지 모델을 한두개 정도 더 ...
SPEAKER_05: 분명히 인베너스 발생할 거거든요.
SPEAKER_05: 그래서 그 문제 있으면은 금요일에 가고 목요일에 요청을 하시거든요.
SPEAKER_05: 혹시 코드는 지금 찾기 이상은 없겠나요?
SPEAKER_01: 네 그 뭐냐 제가 일단 간단하게는 써보고선 이거를 제 코랩으로 작성을 해가지고 코랩 쪽에서 자동완성 되는 거랑 GPT한테 물어봐 가면서 해서 지금 만들기는 했는데 데이터를 데이터만 CSB를 똑같...
SPEAKER_05: 레이블링 공부
SPEAKER_05: 레이블링 이거 한거에요?
SPEAKER_01: 1이 더 많네요 네 이거가 제가 뒷부분에 그거를 추가를 했었어요 그 300개가 더 늘어나 원래 1700개였는데 300개의 그 애매한 표현들 중에서 1로 넣어야 되는 것들을 더 넣었어요 이거 정확...
SPEAKER_01: , 일관성이 조금 부족한 분들이 있을 거란 말씀이십니다.
SPEAKER_04: 프로든드 엔드 진행사항은 어떻게 되고 있죠?
SPEAKER_01: , 이거는 결정 사항이 아니라 확인하는 부분이라서 저건 0이거든요.
SPEAKER_01: 이것도 예시로 제가 넣은 것들 중에 있었던 건데.
SPEAKER_05: 수율을 확인해서 보내야 하나?
SPEAKER_01: 수율 관련 내용 다시 한 번 확인 부탁드릴게요 요거는 확인을 얘기를 하는 거지 어떤 결정 사안이나 이런 게 아니라서 읽고서 하고 넘어갔는데 여러분들 티켓할 때 티켓 기준만 있으면 될 것 같은데
SPEAKER_05: 저런 건 티켓은 안 다겠다는 거죠, 앞으로?
SPEAKER_01: 이런 내용 같은 경우는 확인 요청이기 때문에 저는 조금 중요도를 낮게 생각을 했거든요.

=== 청크 구분 ===

SPEAKER_01: 1이 더 많네요 네 이거가 제가 뒷부분에 그거를 추가를 했었어요 그 300개가 더 늘어나 원래 1700개였는데 300개의 그 애매한 표현들 중에서 1로 넣어야 되는 것들을 더 넣었어요 이거 정확...
SPEAKER_01: , 일관성이 조금 부족한 분들이 있을 거란 말씀이십니다.
SPEAKER_04: 프로든드 엔드 진행사항은 어떻게 되고 있죠?
SPEAKER_01: , 이거는 결정 사항이 아니라 확인하는 부분이라서 저건 0이거든요.
SPEAKER_01: 이것도 예시로 제가 넣은 것들 중에 있었던 건데.
SPEAKER_05: 수율을 확인해서 보내야 하나?
SPEAKER_01: 수율 관련 내용 다시 한 번 확인 부탁드릴게요 요거는 확인을 얘기를 하는 거지 어떤 결정 사안이나 이런 게 아니라서 읽고서 하고 넘어갔는데 여러분들 티켓할 때 티켓 기준만 있으면 될 것 같은데
SPEAKER_05: 저런 건 티켓은 안 다겠다는 거죠, 앞으로?
SPEAKER_01: 이런 내용 같은 경우는 확인 요청이기 때문에 저는 조금 중요도를 낮게 생각을 했거든요.
SPEAKER_05: 여러분들이 결정하면 그대로 갑니다.
SPEAKER_05: 결정 기준이 명확하게 있으면 생각 없습니다.
SPEAKER_01: 근데 이거, , 근데 아까도 말씀드렸지만 이게 수동으로 하는데 멘토님도 한 100개 정도 만들어서 이제 그걸로 레벨링을 하고
SPEAKER_05: 나온 거를 이제 비교해서 한다고 했는데 100개 수동에 그 어쨌건 이것도 수동으로 해야 되는 거니까 이거의 신뢰도를 어떻게 생각을 해야 될지 이거가 조금 걱정이기는 해요 이게 지금 엄청 중요한 ...
SPEAKER_05: 보통 알바생들은 많이 쓰거든요.
SPEAKER_05: 알바생들은 3개 정도, 저희도 한 달 동안 레이블링을 다 해봐요.
SPEAKER_05: 그 다음에 이렇게 한 번 잡는 게 첫 번째고, 진행할 때 여기 계신 명군님이랑 슬기님, 주영님이 같이 레이블링을 따로따로 한다고 해볼게요.
SPEAKER_05: 데이터를 하나씩 보이고 하다가 저희는 시스템으로 만들었죠.
SPEAKER_05: 이 두 명은 한 번 같은 데이터를 레이블링을 하면 갑자기 랜덤으로.
SPEAKER_05: 이 조성은 어떤 데이터를 만들는지 모르겠죠.
SPEAKER_05: 똑같은 데서 레이블링 했다라고 하면 상관이 없는데, 레이블링은 잘못됐어요.
SPEAKER_05: 그럼 만약에 필요한 사람이, 예를 들어 세이디 누누님이 얘를 영렬하게 레이블링을 하고 다른 사람이 다 일로 레이블링을 하겠어요.
SPEAKER_05: 그래서 하나의 데이터를 알바생들 생각만 했을 때, 하나의 데이터를 한 명만 보고 넘어가지가 않아요.
SPEAKER_05: 100개는 똑같이 다 할 필요 없고, 크로스맨이 최적화 아이보리즘 때문에 겹치는 거 10개 정도만 하게 하고, 근데 중독이 이거 100개 할 때

=== 청크 구분 ===

SPEAKER_05: 보통 알바생들은 많이 쓰거든요.
SPEAKER_05: 알바생들은 3개 정도, 저희도 한 달 동안 레이블링을 다 해봐요.
SPEAKER_05: 그 다음에 이렇게 한 번 잡는 게 첫 번째고, 진행할 때 여기 계신 명군님이랑 슬기님, 주영님이 같이 레이블링을 따로따로 한다고 해볼게요.
SPEAKER_05: 데이터를 하나씩 보이고 하다가 저희는 시스템으로 만들었죠.
SPEAKER_05: 이 두 명은 한 번 같은 데이터를 레이블링을 하면 갑자기 랜덤으로.
SPEAKER_05: 이 조성은 어떤 데이터를 만들는지 모르겠죠.
SPEAKER_05: 똑같은 데서 레이블링 했다라고 하면 상관이 없는데, 레이블링은 잘못됐어요.
SPEAKER_05: 그럼 만약에 필요한 사람이, 예를 들어 세이디 누누님이 얘를 영렬하게 레이블링을 하고 다른 사람이 다 일로 레이블링을 하겠어요.
SPEAKER_05: 그래서 하나의 데이터를 알바생들 생각만 했을 때, 하나의 데이터를 한 명만 보고 넘어가지가 않아요.
SPEAKER_05: 100개는 똑같이 다 할 필요 없고, 크로스맨이 최적화 아이보리즘 때문에 겹치는 거 10개 정도만 하게 하고, 근데 중독이 이거 100개 할 때 내가 잘못한 게 아니라 내 생각에는 이런 기준이었어.
SPEAKER_05: 대충 레이블링 하기 아니라 생각이 다 정의가 다른 거지.
SPEAKER_01: 그거 돌리기 전에 제가 레이블링에 대한 기준을 저희 테스크 만드는 걸로 해가지고 일단은 1차적인 기준을 같이 놓고 같은 기준을 보면서 레이블링 해서 비교를 해가지고 정하는 걸로 해보도록 하겠습니다.
SPEAKER_05: 그게 데이터 전찰이 결과서나 이런 데 들어가면 좋겠죠?
SPEAKER_05: 참고로 저희 시간 남았으니까 여러가지 관광분들을 얘기해드리면은 셀프 슈퍼바이스 런이 이라는 게 있어요.
SPEAKER_05: 그래서 이건 뭐냐면 레이블링 된 거를 가지고 이제 모델 다섯 개를 만들어요.
SPEAKER_05: 근데 성능 좋다 어느 정도 좋게 나왔을 때 정말 컴퓨터스 높은 거.
SPEAKER_05: 엄청 좋은 컴퓨터에서 나오는 건 정답이다 라고 생각하고 예를 학습 데이터로 넣는 방법이 있어요 그 버튼을 돌리고 다시 예측을 돌리고 높은 컴퓨터를 다시 레이브를 넣고 그럼 지금 순도를 높여가는 ...
SPEAKER_05: 그래서 일반 1부분을 학습해서 학습 데이터를 만든 다음에 학습을 돌려야 해 모델을 한 5개를 돌린 다음에 인터넷에 있는 데이터를 탈 예측을 해봐야 해 예측하는 데이터들 중에서 모델 6개 중에서 ...
SPEAKER_05: 그래서 이런 여러분들이 질문하는 것, 메이블링을 어떻게 해요가 엄청난 리서트 주제 중에 하나입니다.
SPEAKER_05: 매년 다커퍼런스에 논문이 나오는 것 중에 하나가 이런 방법들이 하나씩 포함되어 있어요.
SPEAKER_05: 이것도 여러분들이 관심 있으시면 논문 찾아보시고 연구를 해보시면 괜찮을

=== 청크 구분 ===

SPEAKER_05: 그래서 이건 뭐냐면 레이블링 된 거를 가지고 이제 모델 다섯 개를 만들어요.
SPEAKER_05: 근데 성능 좋다 어느 정도 좋게 나왔을 때 정말 컴퓨터스 높은 거.
SPEAKER_05: 엄청 좋은 컴퓨터에서 나오는 건 정답이다 라고 생각하고 예를 학습 데이터로 넣는 방법이 있어요 그 버튼을 돌리고 다시 예측을 돌리고 높은 컴퓨터를 다시 레이브를 넣고 그럼 지금 순도를 높여가는 ...
SPEAKER_05: 그래서 일반 1부분을 학습해서 학습 데이터를 만든 다음에 학습을 돌려야 해 모델을 한 5개를 돌린 다음에 인터넷에 있는 데이터를 탈 예측을 해봐야 해 예측하는 데이터들 중에서 모델 6개 중에서 ...
SPEAKER_05: 그래서 이런 여러분들이 질문하는 것, 메이블링을 어떻게 해요가 엄청난 리서트 주제 중에 하나입니다.
SPEAKER_05: 매년 다커퍼런스에 논문이 나오는 것 중에 하나가 이런 방법들이 하나씩 포함되어 있어요.
SPEAKER_05: 이것도 여러분들이 관심 있으시면 논문 찾아보시고 연구를 해보시면 괜찮을 것 같아요.
SPEAKER_05: 사람을 어떻게 획기적으로 갈구일 수 있는지 네이블링을 열심히 하는 게 아니라 그렇게까지 갈굴 필요가 있으니까요 지금은 장난스러우고 말하는데 여러분이 회사에 가서 알바생에 100명을 뽑아서 색다를...
SPEAKER_05: 어려워지는 경우는 은근히 많아요.
SPEAKER_05: 그래서 효과적으로 돌리려면 여러 가지 방법들이 있어요.
SPEAKER_01: 일단은 이 인공지능학습결과서는 어차피 지금 다시 써야 되는 부분들도 있고 말씀해주신 부분들 더 추가 해석
SPEAKER_01: 공개를 하도록 하겠고요.
SPEAKER_01: 혹시 중간에 모르겠는 게 있으면 파랑새를 통해서도 아니면 제가 직접 받은 연락을 드리도록 하겠습니다.
SPEAKER_05: 그러면 화면 계획서 적성원에서 할 수 있는데.
SPEAKER_01: 화면 계획서가 저희가 아마 잠시만요.
SPEAKER_01: 화면 설계서가 다음 주 거라서 지금 초한만 했다가 이번 주 거 지금 그 뭐지?
SPEAKER_01: 문서 들어간 것 때문에 지금 그 우선도가 미뤄졌습니다.
SPEAKER_00: 저희 이번 화요일 날 저랑 차인님 두 분 다 시험 때문에 없거든요.
SPEAKER_00: 그래서 다음 주 화요일 날이 돼야지 아마 가능할 것 같습니다.
SPEAKER_04: 다음 주 화요일에는 저희 본사작업은 다음 주에 없죠?
SPEAKER_01: 다음 주에 발표가 화요일 날이 있고요.
SPEAKER_05: 중간 발표요?
SPEAKER_05: 중간 발표 자격이 부분은?

=== 청크 구분 ===

SPEAKER_01: 공개를 하도록 하겠고요.
SPEAKER_01: 혹시 중간에 모르겠는 게 있으면 파랑새를 통해서도 아니면 제가 직접 받은 연락을 드리도록 하겠습니다.
SPEAKER_05: 그러면 화면 계획서 적성원에서 할 수 있는데.
SPEAKER_01: 화면 계획서가 저희가 아마 잠시만요.
SPEAKER_01: 화면 설계서가 다음 주 거라서 지금 초한만 했다가 이번 주 거 지금 그 뭐지?
SPEAKER_01: 문서 들어간 것 때문에 지금 그 우선도가 미뤄졌습니다.
SPEAKER_00: 저희 이번 화요일 날 저랑 차인님 두 분 다 시험 때문에 없거든요.
SPEAKER_00: 그래서 다음 주 화요일 날이 돼야지 아마 가능할 것 같습니다.
SPEAKER_04: 다음 주 화요일에는 저희 본사작업은 다음 주에 없죠?
SPEAKER_01: 다음 주에 발표가 화요일 날이 있고요.
SPEAKER_05: 중간 발표요?
SPEAKER_05: 중간 발표 자격이 부분은?
SPEAKER_01: 네, 그래서 이번 주말에는 저희가 중간 발표 자료를 준비를 해야 되고 그 다음에 그 외에도 대출해야 되는 게 두 개 있습니다.
SPEAKER_01: 그 중에 하나가 이제 화면 설계서고 다른 하나가 시스템 구성도 아키텍처 부분입니다.
SPEAKER_05: 여러분들 화면 구성은 이제 여러분들 몇 개만이 없어서 쉽게 넘어갈 것 같고, 큰 일들이 없어 보이거든요?
SPEAKER_05: 아키텍처만 신경 써서 하시면 되고 갈게요.
SPEAKER_05: 그럼 차주 화요일에는 아키텍처 리뷰를 하고 두 분의 발표..를 보면 될 것 같아요.
SPEAKER_03: 저희 혹시 다음 주 화요일에 진행하나요?
SPEAKER_01: 네 다음 주 화요일이어서 혹시 가능하시면은 수요일 날 혹시 가능하실지 안 그래도 오늘 여쭤봤죠.
SPEAKER_04: 그럼 다음주에는 목요일에 하세요.
SPEAKER_05: 버튼 학습이라는 평가?
SPEAKER_04: 그러면 지금 CPT 쪽은 두 분이 맡고 계신 거잖아요.
SPEAKER_05: 트랜스포머의 인코더는 지금 두 분이 맡고 있어요.
SPEAKER_05: 근데 막세김님이 트랜스포머의 인코더를 제가 책임지겠다고 얘기를 했거든요.
SPEAKER_05: 그럼 차주 화요일에는 두 명의 발표 세션이 있을 수 있을 것 같아요.
SPEAKER_05: 그래서 트랜스포머의 인코더 부분, 버트, 학습방법이랑 노스콩션 어떻게 돌아가는지 이런 것들을 발표해주시면 좋을 것 같아요.
SPEAKER_05: 토요일이 있으니까 토요일에 발표시전에 가져오는 것 같아요.
SPEAKER_05: 4주 토요일은 제가 없을 예정이라..

=== 청크 구분 ===

SPEAKER_03: 저희 혹시 다음 주 화요일에 진행하나요?
SPEAKER_01: 네 다음 주 화요일이어서 혹시 가능하시면은 수요일 날 혹시 가능하실지 안 그래도 오늘 여쭤봤죠.
SPEAKER_04: 그럼 다음주에는 목요일에 하세요.
SPEAKER_05: 버튼 학습이라는 평가?
SPEAKER_04: 그러면 지금 CPT 쪽은 두 분이 맡고 계신 거잖아요.
SPEAKER_05: 트랜스포머의 인코더는 지금 두 분이 맡고 있어요.
SPEAKER_05: 근데 막세김님이 트랜스포머의 인코더를 제가 책임지겠다고 얘기를 했거든요.
SPEAKER_05: 그럼 차주 화요일에는 두 명의 발표 세션이 있을 수 있을 것 같아요.
SPEAKER_05: 그래서 트랜스포머의 인코더 부분, 버트, 학습방법이랑 노스콩션 어떻게 돌아가는지 이런 것들을 발표해주시면 좋을 것 같아요.
SPEAKER_05: 토요일이 있으니까 토요일에 발표시전에 가져오는 것 같아요.
SPEAKER_05: 4주 토요일은 제가 없을 예정이라..
SPEAKER_05: 그럼 화요일에 발표를 한 번 하고 다음 4주 목요일에 발표 한 번 하고 4주 토요일에 한 번 발표하시죠.
SPEAKER_05: 4주 토요일은 버튼 세션 하는 걸로.
SPEAKER_05: 그리고 모델 별로 지금 아마 KC버튼은 버트랑 큰 의미가 없을 거예요.
SPEAKER_05: 일렉터나 같은 경우에는 아이보리즘이 다르거든요.
SPEAKER_05: 여기에 옵티마이저를 보면 adam warmup이 있어요.
SPEAKER_05: 근데 지금 GPT를 학습할 때도 adam warmup이랑 랜브랑 이런 유스값들을 많이 쓰거든요.
SPEAKER_05: 랜브라는 옵티마이저를 언제 쓰는 거고 adam warmup은 언제 쓰는 거고.
SPEAKER_05: 왜 파인트링 할 때는 adam warmup을 주로 쓰고 프리트레이닝 할 때는 랜브를 쓸까?
SPEAKER_05: 이런 거에 대한 고찰, 이런 것들이 여러 가지가 있어요.
SPEAKER_05: 목요일에 발표 세션이 있으니까 토요일에 하시면 될 거 같아요.
SPEAKER_05: 다른 분들이 미리 공유하지 마시고 갖고 왔을 때 미리 공유해서 잘못하지 마시고 딱딱 발표를 하시고 다른 분들은 질문을 계속 해주세요.
SPEAKER_05: 발표를 드릴 때 계속 의문점을 머리를 떠올려야 돼요.
SPEAKER_01: 24일 26일입니다.
SPEAKER_00: 일단 차주는 제가 없어요.
SPEAKER_00: 차주 주말은 제가 아예 안 되고 3분 안 되네요.
SPEAKER_01: 만약에 27일을 하게 되면 저랑 준성님만 안 되는 거가 되고요 26일은 3분이 안 되셔서 그러면은 이걸 맞

=== 청크 구분 ===

SPEAKER_05: 근데 지금 GPT를 학습할 때도 adam warmup이랑 랜브랑 이런 유스값들을 많이 쓰거든요.
SPEAKER_05: 랜브라는 옵티마이저를 언제 쓰는 거고 adam warmup은 언제 쓰는 거고.
SPEAKER_05: 왜 파인트링 할 때는 adam warmup을 주로 쓰고 프리트레이닝 할 때는 랜브를 쓸까?
SPEAKER_05: 이런 거에 대한 고찰, 이런 것들이 여러 가지가 있어요.
SPEAKER_05: 목요일에 발표 세션이 있으니까 토요일에 하시면 될 거 같아요.
SPEAKER_05: 다른 분들이 미리 공유하지 마시고 갖고 왔을 때 미리 공유해서 잘못하지 마시고 딱딱 발표를 하시고 다른 분들은 질문을 계속 해주세요.
SPEAKER_05: 발표를 드릴 때 계속 의문점을 머리를 떠올려야 돼요.
SPEAKER_01: 24일 26일입니다.
SPEAKER_00: 일단 차주는 제가 없어요.
SPEAKER_00: 차주 주말은 제가 아예 안 되고 3분 안 되네요.
SPEAKER_01: 만약에 27일을 하게 되면 저랑 준성님만 안 되는 거가 되고요 26일은 3분이 안 되셔서 그러면은 이걸 맞출 수가 없고 27일 그러면 되는 거 아니에요?